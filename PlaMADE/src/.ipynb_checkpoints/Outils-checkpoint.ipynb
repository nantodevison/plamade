{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOURRE-TOUT pour scrips PlaMADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\geopandas\\_compat.py:84: UserWarning: The Shapely GEOS version (3.4.3-CAPI-1.8.3 r4285) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import Connexion_Transfert as ct\n",
    "import Outils as O\n",
    "from geoalchemy2 import Geometry,WKTElement\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.geometry.point import Point\n",
    "from shapely.geometry.multipoint import MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import speedups\n",
    "speedups.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees'\n",
    "#dézipper tous les dossier de Gérard\n",
    "for root,dirs, files in os.walk(dossierSrc) : \n",
    "    for f in files : \n",
    "        if f.endswith('.zip') : \n",
    "            cheminFichier=os.path.join(root, f)\n",
    "            print(cheminFichier[:-4])\n",
    "            try:\n",
    "                with zipfile.ZipFile(cheminFichier) as z:\n",
    "                    z.extractall(cheminFichier[:-4])\n",
    "                    print(f\"fichier extrait {cheminFichier[:-4]}\")\n",
    "            except:\n",
    "                print(f\"pb extraction sur dossier {cheminFichier[:-4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. creer une bdd des fichiers geostandardises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour traiter tous les fichiers d'un dossier général.suppose que la structure des tables a déjà été crée (par exemple avec l'import des des fichiers pouis truncate)\n",
    "dossierSrc=r'D:\\Boulot\\PlaMADE\\Ile-de-france\\75-Paris\\75'\n",
    "coupleFichierTable=(('N_ROUTIER_ALLURE','allure_national'),('N_ROUTIER_REVETEMENT','rvt_national'),('N_ROUTIER_ROUTE','route_national'),\n",
    "                    ('N_ROUTIER_TRAFIC','trafic_national'),('N_ROUTIER_VITESSE','vts_national'))\n",
    "#dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Auvergne-Rhone-Alpes\\Donnees_geostandardisees\\Route01_v2_dec2020'\n",
    "listEreur=[]\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    for root,dirs, files in os.walk(dossierSrc) : \n",
    "        for f in files :\n",
    "            if f.endswith(('.shp', '.dbf')) : \n",
    "                print(os.path.join(root,f))\n",
    "                if f.endswith('.shp') and 'N_ROUTIER_TRONCON' in f :\n",
    "                    try :\n",
    "                        ct.ogr2ogr_shp2pg(c.connstringOgr,os.path.join(root,f),\n",
    "                                              schema='geostandardise_src', table='troncon_national',\n",
    "                                              SRID=None,geotype='MULTILINESTRINGZ', dims=3, creationMode='-append -update',encodageClient='UTF-8', version_simple=True)\n",
    "                    except Exception as e: \n",
    "                        listEreur.append({'fichier': f, erreur : e})\n",
    "                else : \n",
    "                    for fich,t in coupleFichierTable :\n",
    "                        try : \n",
    "                            if fich in f.upper() and f.endswith('.dbf') : \n",
    "                                ct.ogr2ogr_shp2pg(c.connstringOgr,os.path.join(root,f),\n",
    "                                                  schema='geostandardise_src', table=t, SRID=None,geotype=None, dims=None, creationMode='-append -update',encodageClient='UTF-8', requeteSql='', version_simple=True)\n",
    "                            elif fich in f.upper() and f.endswith('.csv') :\n",
    "                                df = pd.read_csv(os.path.join(root,f), \n",
    "                                                 keep_default_na=False)\n",
    "                                df.columns=[c.lower() for c in df.columns]\n",
    "                                df.drop(colonnesEnTrop,axis=1).to_sql(t,c.sqlAlchemyConn,'geostandardise_src', if_exists='append', index=False )\n",
    "                        except Exception as e: \n",
    "                            listEreur.append({'fichier': f, 'erreur' : e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si les donnees trafic, vts, allure , rvt sont en csv, le plus simple c'est pandas : \n",
    "dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Bretagne'\n",
    "coupleFichierTable=(('N_ROUTIER_ALLURE','allure_national'),('N_ROUTIER_REVETEMENT','rvt_national'),('N_ROUTIER_ROUTE','route_national'),\n",
    "                    ('N_ROUTIER_TRAFIC','trafic_national'),('N_ROUTIER_VITESSE','vts_national'))\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    for root,dirs, files in os.walk(dossierSrc) : \n",
    "            for f in files :\n",
    "                if f.endswith('.csv') :\n",
    "                    for fich,t in coupleFichierTable :\n",
    "                        if fich in f.upper() : \n",
    "                            try : \n",
    "                                print(os.path.join(root,f))\n",
    "                                df = pd.read_csv(os.path.join(root,f), \n",
    "                                                keep_default_na=False)\n",
    "                                df.columns=[c.lower() for c in df.columns]\n",
    "                                dfref=pd.read_sql(f'select * from geostandardise_src.{t} limit 1',c.sqlAlchemyConn)\n",
    "                                colonnesEnTrop=[c.lower() for c in df.columns if c not in dfref.columns]\n",
    "                                df.drop(colonnesEnTrop,axis=1).to_sql(t,c.sqlAlchemyConn,'geostandardise_src', if_exists='append', index=False )\n",
    "                            except Exception as e :\n",
    "                                print(f'Erreur sur : {os.path.join(root,f)} : {e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour test sur un dept\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr,r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Bretagne\\35\\N_ROUTIER_TRONCON_L_035.shp',\n",
    "                                              schema='geostandardise_src', table='troncon_national',\n",
    "                                              SRID='2154',geotype='MULTILINESTRING', dims=3, creationMode='-append -update',encodageClient='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sur un fichier\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr,r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Auvergne_Rhone_Alpes\\Donnees_geostandardisees\\Route01_v2_dec2020\\N_ROUTIER_ALLURE_001.dbf',\n",
    "                                                  schema='geostandardise_src', table='allure_national', SRID=None,geotype=None, dims=None, creationMode='-append -update',encodageClient='UTF-8', requeteSql='', version_simple=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Générer un fichier unique trafic RD\n",
    "> L'idée est de se baser sur le fichier de résumé des fichiers gestionnaires et de leurs attributs pour produire un fichier concaténé, avec des attributs uniques relatifs au :\n",
    "- tmja\n",
    "- pcpl\n",
    "- nom de la voie\n",
    "- annee du trafic\n",
    "- fichier source (sur Box internet)\n",
    "- nom de la source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Principe mise en forme des fichiers \n",
    ">> Pour faire ça on va aller chercher le [fichier de synthses des données RD] (https://cerema.app.box.com/folder/132749694470/Synthese_type_fichier.ods).\n",
    "dans l'onglet trafic, on va itérer sur chaque ligne (donc récupération du tuple de valeur) : \n",
    ">> On limite l'analyse aux données présentant un colonne valide='oui' & type='sig' & type_geom='ligne'  \n",
    "1. on récupere la valeur de la colonne \"nom_fichier_trafic\" :\n",
    "    1. si l'extenstion est présente, on va lire le fichier (attention, via box Drive, donc paramètre de raw string en entrée)\n",
    "    1. l'attribut relatif au tmja est toujours présent, celui au pc_pl parfois, comme pour les routes ou l'année, mais comme la fonction rename s'en fout, on fait le rename des 4 colonnes\n",
    "    1. si des formules sont à appliquer, on les applique (liées au pcpl, et nom de route notamment\n",
    "    1. gérer le format des dates pour l'année de mesure\n",
    "    1. ajouter les attributs sur le fichiers sources, le nom de la source, le type de source\n",
    "    1. enregistrer le fichier mise en forme dans le dossier qui va bien (paramètre entrée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir le fichiers de syntheses des données\n",
    "dossierDonneesRd=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD'\n",
    "fichierSynthese=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD\\Synthese_type_fichier.ods'\n",
    "dfFichierSynthese=pd.read_excel(fichierSynthese, sheet_name='trafic',engine='odf', nrows=35, dtype={'dept':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer le generateurde parcours des valeusr en tuple\n",
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion']!='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'ajout des sources de données\n",
    "def ajouterSourceDonnees(tupleNomAttr, dfFichierRenomme, fihcierSource) : \n",
    "    \"\"\"\n",
    "    ajouter les nomsource, fichier source et type de source aux donnees mise en formes\n",
    "    in : \n",
    "        tupleNomAttr : tuple des noms d'attributs recherche dans le fchier source\n",
    "        dfFichierRenomme : gdf : contient la trsucture attributaire prevue, apres calcul\n",
    "        fihcierSource : String : nom du fichier source\n",
    "    \"\"\"\n",
    "    dfFichierRenomme['nomsource']='CD_'+tupleNomAttr.dept\n",
    "    dfFichierRenomme['fichie_src']=fihcierSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'ouverture et reprojection en 2154\n",
    "def ouvrirReprojeter(cheminFichier, tupleNomAttr):\n",
    "    \"\"\"\n",
    "    tupleNomAttr : tuple des noms d'attributs recherche dans le fchier source\n",
    "    \"\"\"\n",
    "    dfFichierSource=gp.read_file(cheminFichier, crs=tupleNomAttr.projection)\n",
    "    dfFichierSource=dfFichierSource.to_crs('epsg:2154')\n",
    "    return dfFichierSource\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de calcul regroupant les traitements propres a chaque dept ayant des regles de gestion\n",
    "def calculSpecifique(dfFichierSource, tupleNomAttr, listAttrNonNull) : \n",
    "    \"\"\"\n",
    "    calculer les valeur de tmja, pcpl, nom route et année dans les cas particuklier ou des regles de gestion sont necessaire\n",
    "    in : \n",
    "        dept : string : departement sur 3 caracteres\n",
    "        dfFichierSource : gdf : gdf issue des fichiers osurces gestionnaiere\n",
    "        tupleNomAttr : tuple des noms d'attributs recherche dans le fchier source\n",
    "        listAttrNonNull : list des attributs present dans le fichier (ayant une valuer non nulle)\n",
    "    out : \n",
    "        dfFichierRenomme : gdf : contient la trsucture attributaire prevue, apres calcul\n",
    "    \"\"\"\n",
    "    if tupleNomAttr.dept=='012' : \n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TMJATV2015'] if not pd.isnull(x['TMJATV2015']) else x['TMJA_TV'], axis=1)\n",
    "        dfFichierSource['annee']=dfFichierSource.apply(lambda x : re.match('2[0-9]{3]',x['COMMENTAIR']) if not pd.isnull(x['COMMENTAIR']) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={tupleNomAttr.nom_attr_pcpl:'pcpl', tupleNomAttr.nom_attr_route:'nomRoute'})\n",
    "    elif tupleNomAttr.dept=='025' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TMJA'] if x['%_PL']!='D' else None, axis=1)\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['%_PL']) if x['%_PL']!='D' else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={tupleNomAttr.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='027' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.F_PL.apply(lambda x : x.replace('%','').replace(',','.') if not pd.isnull(x) else None)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee',tupleNomAttr.nom_attr_route:'nomRoute'})\n",
    "    elif tupleNomAttr.dept=='031' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.route.apply(lambda x : O.epurationNomRoute(x))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='037' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.idroute.apply(lambda x : x.split('_')[1])\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='046': \n",
    "        dfFichierSource['trafic']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[0] if not pd.isnull(x) else None)\n",
    "        dfFichierSource['annee']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[1][:-1] if not pd.isnull(x) and '(' in x else None)\n",
    "        dfFichierSource['pcpl']=dfFichierSource['%PL'].apply(lambda x : float(x)*100 if not pd.isnull(x) else None)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource['RD'].apply(lambda x : x.replace(' ','').replace('RD','D'))\n",
    "        dfFichierRenomme=dfFichierSource.copy()\n",
    "    elif tupleNomAttr.dept=='049' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.Route.apply(lambda x : O.epurationNomRoute(x[3:]))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='052' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['MJA_PL']/x['MJA_TV']*100) if not pd.isnull(x['MJA_TV']) else None, axis=1)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.Route.apply(lambda x : O.epurationNomRoute(x))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='058' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TRAFFIC_VL']+x['TRAFFIC_PL'], axis=1)\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['TRAFFIC_PL']/(x['TRAFFIC_VL']+x['TRAFFIC_PL'])*100) if x['TRAFFIC_VL']+x['TRAFFIC_PL']>0 else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={tupleNomAttr.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='059' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.VOIE.apply(lambda x : O.epurationNomRoute(x[1:]))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='060' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.PCT_PL_SEM.apply(lambda x : x.replace('%PL','') if not x=='%PL' else None)\n",
    "        dfFichierSource['annee']=dfFichierSource.DATE_COMPT.str[-4:]\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_route:'nomRoute'})\n",
    "    elif tupleNomAttr.dept=='070':\n",
    "        for c in [f'TA_TV{i}' for i in range(10,19)]: \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False, axis=1),'trafic']= dfFichierSource[c]\n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1),'pcpl']=(dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c.replace('TV','PL')]), axis=1)/\n",
    "              dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c]), axis=1)*100)                \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False , axis=1),'annee']= f'20{c[-2:]}'\n",
    "            dfFichierRenomme=dfFichierSource.rename(columns={tupleNomAttr.nom_attr_route:'nomRoute'})\n",
    "    elif tupleNomAttr.dept=='075' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : (x['MT']*12)+(x['ME']*4)+(x['MN']*8) if not (pd.isnull(x['MT']) and pd.isnull(x['ME']) and pd.isnull(x['MN'])) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={tupleNomAttr.nom_attr_pcpl:'pcpl', tupleNomAttr.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept in ('080','082') :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource[tupleNomAttr.nom_attr_route].str[3:]\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept =='076' : \n",
    "        dfFichierSource['nomRoute']=dfFichierSource[tupleNomAttr.nom_attr_route].apply(lambda x : O.epurationNomRoute(x[3:]) if x[:2]!='VC' else x )\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',tupleNomAttr.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='077' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['PLTMJA']/x['TVTMJA']*100) if not pd.isnull(x['TVTMJA']) else None, axis=1)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.ROUTE.apply(lambda x : O.epurationNomRoute(x[2:]))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee'})\n",
    "    elif tupleNomAttr.dept=='083' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.ROUTE.apply(lambda x : O.epurationNomRoute(x[3:]))\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : int(x['MJA_2018']) if int(x['MJA_2018'])>0 else int(x['MJA_2017']), axis=1)\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : x['PL_2018'] if int(x['MJA_2018'])>0 else str(int(x['PL_2017'])/10), axis=1)\n",
    "        dfFichierSource['annee']=dfFichierSource.apply(lambda x : '2018' if int(x['MJA_2018'])>0 else '2017', axis=1)                                                                                                  \n",
    "        dfFichierRenomme=dfFichierSource.copy()\n",
    "    return dfFichierRenomme[listAttrNonNull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012\n",
      "013\n",
      "027\n",
      "035\n",
      "036\n",
      "037\n",
      "044\n",
      "045\n",
      "048\n",
      "049\n",
      "050\n",
      "052\n",
      "058\n",
      "059\n",
      "060\n",
      "066\n",
      "067\n",
      "068\n",
      "071\n",
      "075\n",
      "076\n",
      "077\n",
      "080\n",
      "082\n",
      "083\n",
      "092\n"
     ]
    }
   ],
   "source": [
    "#Concat des donnees \n",
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            \"\"\"if t.dept  not in  ('027') : \n",
    "                continue\"\"\"\n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #print(listAttrNonNull)\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('012','027', '037', '049', '052', '058', '059', '060', '075', '077','082', '083', '076','080'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcat=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "#tagguer les geoms nulles \n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'D:\\Boulot\\AffairesEnCours\\plamade\\RDs\\concat\\RD_concatenation_trafic_lineaire.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.2 Principe mise en forme des fichiers ponctuels\n",
    ">> on va garder la structure précédente, mais il va aussi falloir ajouter les 2 jeu de données en tableur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion']!='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002\n",
      "008\n",
      "025\n",
      "031\n",
      "039\n",
      "046\n",
      "070\n",
      "089\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            \"\"\"if t.dept  not in  ('046') : \n",
    "                continue\"\"\"\n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #print(f)\n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('025','031', '070', '046'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "#tagguer les geoms nulles \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "dfConcat.loc[dfConcat.nomsource=='CD_008', 'annee']='2018'\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)\n",
    "\n",
    "#toutes les geoms en multi\n",
    "dfConcat[\"geometry\"] = [MultiPoint([feature]) if isinstance(feature, Point) else feature for feature in dfConcat[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'D:\\Boulot\\AffairesEnCours\\plamade\\RDs\\concat\\RD_concatenation_trafic_ponctuel.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [f'TA_TV{i}' for i in range(10,19)]: \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False, axis=1),'trafic']= dfFichierSource[c]\n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1),'pcpl']=(dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c.replace('TV','PL')]), axis=1)/\n",
    "              dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c]), axis=1)*100)                \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False , axis=1),'annee']= f'20{c[-2:]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierSource.loc[pd.isnull(dfFichierSource.annee)]\n",
    "dfFichierSource.loc[dfFichierSource.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True)]\n",
    "dfFichierSource.loc[dfFichierSource.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierSource['trafic']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[0] if not pd.isnull(x) else None)\n",
    "dfFichierSource['annee']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[1][:-1] if not pd.isnull(x) and '(' in x else None)\n",
    "dfFichierSource['pcpl']=dfFichierSource['%PL'].apply(lambda x : float(x)*100 if not pd.isnull(x) else None)\n",
    "dfFichierSource['nomRoute']=dfFichierSource['RD'].apply(lambda x : x.replace(' ','').replace('RD','D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFichierSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trafic</th>\n",
       "      <th>pcpl</th>\n",
       "      <th>nomRoute</th>\n",
       "      <th>annee</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nomsource</th>\n",
       "      <th>fichie_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D620</td>\n",
       "      <td>2014</td>\n",
       "      <td>POINT (574957.400 6375488.700)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12260</td>\n",
       "      <td>4.46</td>\n",
       "      <td>D620</td>\n",
       "      <td>2014</td>\n",
       "      <td>POINT (576039.000 6372752.100)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D8</td>\n",
       "      <td>2011</td>\n",
       "      <td>POINT (573839.900 6375058.600)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D8</td>\n",
       "      <td>2009</td>\n",
       "      <td>POINT (574449.100 6374950.700)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10348</td>\n",
       "      <td>3.12</td>\n",
       "      <td>D8</td>\n",
       "      <td>2009</td>\n",
       "      <td>POINT (574880.600 6373961.200)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9020</td>\n",
       "      <td>3.97</td>\n",
       "      <td>D8</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (575191.900 6374028.300)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D811</td>\n",
       "      <td>2012</td>\n",
       "      <td>POINT (574969.800 6375553.700)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11225</td>\n",
       "      <td>5.96</td>\n",
       "      <td>D811</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (574119.961 6376756.430)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9417</td>\n",
       "      <td>6.28</td>\n",
       "      <td>D811</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (571469.775 6379355.856)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D820</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (579784.052 6423589.409)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D820</td>\n",
       "      <td>2012</td>\n",
       "      <td>POINT (574919.786 6375503.886)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8908</td>\n",
       "      <td>10.16</td>\n",
       "      <td>D820</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (574219.855 6374871.567)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D820</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (575923.266 6370855.415)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12423</td>\n",
       "      <td>7.85</td>\n",
       "      <td>D820</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (575533.200 6369684.600)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8520</td>\n",
       "      <td>9.17</td>\n",
       "      <td>D820</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (575969.972 6368395.054)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10252</td>\n",
       "      <td>4.38</td>\n",
       "      <td>D167</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (576544.100 6373476.500)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7869</td>\n",
       "      <td>5.37</td>\n",
       "      <td>D653</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (576137.100 6373411.800)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10247</td>\n",
       "      <td>4.70</td>\n",
       "      <td>D911</td>\n",
       "      <td>2013</td>\n",
       "      <td>POINT (577309.788 6374946.707)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10090</td>\n",
       "      <td>7.77</td>\n",
       "      <td>D840</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (626312.788 6386975.491)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11617</td>\n",
       "      <td>6.33</td>\n",
       "      <td>D840</td>\n",
       "      <td>2018</td>\n",
       "      <td>POINT (625850.264 6388350.683)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7474</td>\n",
       "      <td>4.30</td>\n",
       "      <td>D813</td>\n",
       "      <td>2014</td>\n",
       "      <td>POINT (620633.626 6388941.285)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6377</td>\n",
       "      <td>5.11</td>\n",
       "      <td>D8013</td>\n",
       "      <td>2014</td>\n",
       "      <td>POINT (622690.623 6390368.213)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10043</td>\n",
       "      <td>5.55</td>\n",
       "      <td>D673</td>\n",
       "      <td>2014</td>\n",
       "      <td>POINT (573094.269 6405963.639)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D673</td>\n",
       "      <td>2011</td>\n",
       "      <td>POINT (572307.313 6405614.882)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D673</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (571955.163 6405374.249)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D673</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (571811.890 6405385.280)</td>\n",
       "      <td>CD_046</td>\n",
       "      <td>geolocalisation_Cerema.shp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trafic   pcpl nomRoute annee                        geometry nomsource  \\\n",
       "0   11723    NaN     D620  2014  POINT (574957.400 6375488.700)    CD_046   \n",
       "1   12260   4.46     D620  2014  POINT (576039.000 6372752.100)    CD_046   \n",
       "2   11610    NaN       D8  2011  POINT (573839.900 6375058.600)    CD_046   \n",
       "3   10750    NaN       D8  2009  POINT (574449.100 6374950.700)    CD_046   \n",
       "4   10348   3.12       D8  2009  POINT (574880.600 6373961.200)    CD_046   \n",
       "5    9020   3.97       D8  2015  POINT (575191.900 6374028.300)    CD_046   \n",
       "6   13589    NaN     D811  2012  POINT (574969.800 6375553.700)    CD_046   \n",
       "7   11225   5.96     D811  2018  POINT (574119.961 6376756.430)    CD_046   \n",
       "8    9417   6.28     D811  2018  POINT (571469.775 6379355.856)    CD_046   \n",
       "9    9442    NaN     D820  2018  POINT (579784.052 6423589.409)    CD_046   \n",
       "10  15193    NaN     D820  2012  POINT (574919.786 6375503.886)    CD_046   \n",
       "11   8908  10.16     D820  2018  POINT (574219.855 6374871.567)    CD_046   \n",
       "12  18087    NaN     D820  2015  POINT (575923.266 6370855.415)    CD_046   \n",
       "13  12423   7.85     D820  2018  POINT (575533.200 6369684.600)    CD_046   \n",
       "14   8520   9.17     D820  2018  POINT (575969.972 6368395.054)    CD_046   \n",
       "15  10252   4.38     D167  2015  POINT (576544.100 6373476.500)    CD_046   \n",
       "16   7869   5.37     D653  2015  POINT (576137.100 6373411.800)    CD_046   \n",
       "17  10247   4.70     D911  2013  POINT (577309.788 6374946.707)    CD_046   \n",
       "18  10090   7.77     D840  2018  POINT (626312.788 6386975.491)    CD_046   \n",
       "19  11617   6.33     D840  2018  POINT (625850.264 6388350.683)    CD_046   \n",
       "20   7474   4.30     D813  2014  POINT (620633.626 6388941.285)    CD_046   \n",
       "21   6377   5.11    D8013  2014  POINT (622690.623 6390368.213)    CD_046   \n",
       "22  10043   5.55     D673  2014  POINT (573094.269 6405963.639)    CD_046   \n",
       "23   6560    NaN     D673  2011  POINT (572307.313 6405614.882)    CD_046   \n",
       "24   None    NaN     D673  None  POINT (571955.163 6405374.249)    CD_046   \n",
       "25  11015    NaN     D673  None  POINT (571811.890 6405385.280)    CD_046   \n",
       "\n",
       "                    fichie_src  \n",
       "0   geolocalisation_Cerema.shp  \n",
       "1   geolocalisation_Cerema.shp  \n",
       "2   geolocalisation_Cerema.shp  \n",
       "3   geolocalisation_Cerema.shp  \n",
       "4   geolocalisation_Cerema.shp  \n",
       "5   geolocalisation_Cerema.shp  \n",
       "6   geolocalisation_Cerema.shp  \n",
       "7   geolocalisation_Cerema.shp  \n",
       "8   geolocalisation_Cerema.shp  \n",
       "9   geolocalisation_Cerema.shp  \n",
       "10  geolocalisation_Cerema.shp  \n",
       "11  geolocalisation_Cerema.shp  \n",
       "12  geolocalisation_Cerema.shp  \n",
       "13  geolocalisation_Cerema.shp  \n",
       "14  geolocalisation_Cerema.shp  \n",
       "15  geolocalisation_Cerema.shp  \n",
       "16  geolocalisation_Cerema.shp  \n",
       "17  geolocalisation_Cerema.shp  \n",
       "18  geolocalisation_Cerema.shp  \n",
       "19  geolocalisation_Cerema.shp  \n",
       "20  geolocalisation_Cerema.shp  \n",
       "21  geolocalisation_Cerema.shp  \n",
       "22  geolocalisation_Cerema.shp  \n",
       "23  geolocalisation_Cerema.shp  \n",
       "24  geolocalisation_Cerema.shp  \n",
       "25  geolocalisation_Cerema.shp  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfConcatFixe.loc[dfConcatFixe.nomsource=='CD_046']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>nom_fichier_trafic</th>\n",
       "      <th>valide</th>\n",
       "      <th>type</th>\n",
       "      <th>type_geom</th>\n",
       "      <th>nom_attr_trafic</th>\n",
       "      <th>nom_attr_pcpl</th>\n",
       "      <th>nom_attr_route</th>\n",
       "      <th>nom_attr_annee</th>\n",
       "      <th>projection</th>\n",
       "      <th>regles_gestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>geolocalisation_pt_comptage_Cerema.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TMJA</td>\n",
       "      <td>%PL</td>\n",
       "      <td>ROUTE</td>\n",
       "      <td>ANNÉE</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008</td>\n",
       "      <td>BZ_Compil_trafic_2018 du 08.SHP</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TMJA_18</td>\n",
       "      <td>PCT_PL_18</td>\n",
       "      <td>ROUTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>025</td>\n",
       "      <td>2019_12_12_Points_Comptage_CD25.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TMJA</td>\n",
       "      <td>%_PL</td>\n",
       "      <td>AXE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>Trafic, pcpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>031</td>\n",
       "      <td>CD31-Haute-Garonne.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>tmja_tra</td>\n",
       "      <td>pl_tra</td>\n",
       "      <td>route</td>\n",
       "      <td>annee_tra</td>\n",
       "      <td>Epsg:4326</td>\n",
       "      <td>route</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>039</td>\n",
       "      <td>RO_GP_COMPT_PONCT.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TV</td>\n",
       "      <td>TAUX_PL</td>\n",
       "      <td>AXE</td>\n",
       "      <td>ANNEE</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>070</td>\n",
       "      <td>Trafic 2010 - 2018 CD 70.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TA_TV18</td>\n",
       "      <td>POURCENT_P</td>\n",
       "      <td>ROUTE</td>\n",
       "      <td>Tous</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>089</td>\n",
       "      <td>2020-02-26__Trafic_Bruit(2018)_du_89.shp</td>\n",
       "      <td>oui</td>\n",
       "      <td>sig</td>\n",
       "      <td>point</td>\n",
       "      <td>TMJA,N,9,0</td>\n",
       "      <td>%_PL,N,3,2</td>\n",
       "      <td>NOM_RUE,C,</td>\n",
       "      <td>DATE,D</td>\n",
       "      <td>Epsg:2154</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dept                        nom_fichier_trafic valide type type_geom  \\\n",
       "0   002    geolocalisation_pt_comptage_Cerema.shp    oui  sig     point   \n",
       "1   008           BZ_Compil_trafic_2018 du 08.SHP    oui  sig     point   \n",
       "5   025       2019_12_12_Points_Comptage_CD25.shp    oui  sig     point   \n",
       "7   031                    CD31-Haute-Garonne.shp    oui  sig     point   \n",
       "11  039                     RO_GP_COMPT_PONCT.shp    oui  sig     point   \n",
       "25  070              Trafic 2010 - 2018 CD 70.shp    oui  sig     point   \n",
       "33  089  2020-02-26__Trafic_Bruit(2018)_du_89.shp    oui  sig     point   \n",
       "\n",
       "   nom_attr_trafic nom_attr_pcpl nom_attr_route nom_attr_annee projection  \\\n",
       "0             TMJA           %PL          ROUTE          ANNÉE  Epsg:2154   \n",
       "1          TMJA_18     PCT_PL_18          ROUTE            NaN  Epsg:2154   \n",
       "5             TMJA          %_PL            AXE            NaN  Epsg:2154   \n",
       "7         tmja_tra        pl_tra          route      annee_tra  Epsg:4326   \n",
       "11              TV       TAUX_PL            AXE          ANNEE  Epsg:2154   \n",
       "25         TA_TV18    POURCENT_P          ROUTE           Tous  Epsg:2154   \n",
       "33      TMJA,N,9,0    %_PL,N,3,2     NOM_RUE,C,         DATE,D  Epsg:2154   \n",
       "\n",
       "   regles_gestion  \n",
       "0             non  \n",
       "1             non  \n",
       "5    Trafic, pcpl  \n",
       "7           route  \n",
       "11            non  \n",
       "25            non  \n",
       "33            non  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNettoyees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
