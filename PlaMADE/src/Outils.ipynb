{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOURRE-TOUT pour scrips PlaMADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\geopandas\\_compat.py:84: UserWarning: The Shapely GEOS version (3.4.3-CAPI-1.8.3 r4285) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import Connexion_Transfert as ct\n",
    "import Outils as O\n",
    "from geoalchemy2 import Geometry,WKTElement\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.geometry.point import Point\n",
    "from shapely.geometry.multipoint import MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import speedups\n",
    "speedups.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees'\n",
    "#dézipper tous les dossier de Gérard\n",
    "for root,dirs, files in os.walk(dossierSrc) : \n",
    "    for f in files : \n",
    "        if f.endswith('.zip') : \n",
    "            cheminFichier=os.path.join(root, f)\n",
    "            print(cheminFichier[:-4])\n",
    "            try:\n",
    "                with zipfile.ZipFile(cheminFichier) as z:\n",
    "                    z.extractall(cheminFichier[:-4])\n",
    "                    print(f\"fichier extrait {cheminFichier[:-4]}\")\n",
    "            except:\n",
    "                print(f\"pb extraction sur dossier {cheminFichier[:-4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. creer une bdd des fichiers geostandardises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour traiter tous les fichiers d'un dossier général.suppose que la structure des tables a déjà été crée (par exemple avec l'import des des fichiers pouis truncate)\n",
    "dossierSrc=r'D:\\Boulot\\PlaMADE\\Ile-de-france\\75-Paris\\75'\n",
    "coupleFichierTable=(('N_ROUTIER_ALLURE','allure_national'),('N_ROUTIER_REVETEMENT','rvt_national'),('N_ROUTIER_ROUTE','route_national'),\n",
    "                    ('N_ROUTIER_TRAFIC','trafic_national'),('N_ROUTIER_VITESSE','vts_national'))\n",
    "#dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Auvergne-Rhone-Alpes\\Donnees_geostandardisees\\Route01_v2_dec2020'\n",
    "listEreur=[]\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    for root,dirs, files in os.walk(dossierSrc) : \n",
    "        for f in files :\n",
    "            if f.endswith(('.shp', '.dbf')) : \n",
    "                print(os.path.join(root,f))\n",
    "                if f.endswith('.shp') and 'N_ROUTIER_TRONCON' in f :\n",
    "                    try :\n",
    "                        ct.ogr2ogr_shp2pg(c.connstringOgr,os.path.join(root,f),\n",
    "                                              schema='geostandardise_src', table='troncon_national',\n",
    "                                              SRID=None,geotype='MULTILINESTRINGZ', dims=3, creationMode='-append -update',encodageClient='UTF-8', version_simple=True)\n",
    "                    except Exception as e: \n",
    "                        listEreur.append({'fichier': f, erreur : e})\n",
    "                else : \n",
    "                    for fich,t in coupleFichierTable :\n",
    "                        try : \n",
    "                            if fich in f.upper() and f.endswith('.dbf') : \n",
    "                                ct.ogr2ogr_shp2pg(c.connstringOgr,os.path.join(root,f),\n",
    "                                                  schema='geostandardise_src', table=t, SRID=None,geotype=None, dims=None, creationMode='-append -update',encodageClient='UTF-8', requeteSql='', version_simple=True)\n",
    "                            elif fich in f.upper() and f.endswith('.csv') :\n",
    "                                df = pd.read_csv(os.path.join(root,f), \n",
    "                                                 keep_default_na=False)\n",
    "                                df.columns=[c.lower() for c in df.columns]\n",
    "                                df.drop(colonnesEnTrop,axis=1).to_sql(t,c.sqlAlchemyConn,'geostandardise_src', if_exists='append', index=False )\n",
    "                        except Exception as e: \n",
    "                            listEreur.append({'fichier': f, 'erreur' : e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si les donnees trafic, vts, allure , rvt sont en csv, le plus simple c'est pandas : \n",
    "dossierSrc=r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Bretagne'\n",
    "coupleFichierTable=(('N_ROUTIER_ALLURE','allure_national'),('N_ROUTIER_REVETEMENT','rvt_national'),('N_ROUTIER_ROUTE','route_national'),\n",
    "                    ('N_ROUTIER_TRAFIC','trafic_national'),('N_ROUTIER_VITESSE','vts_national'))\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    for root,dirs, files in os.walk(dossierSrc) : \n",
    "            for f in files :\n",
    "                if f.endswith('.csv') :\n",
    "                    for fich,t in coupleFichierTable :\n",
    "                        if fich in f.upper() : \n",
    "                            try : \n",
    "                                print(os.path.join(root,f))\n",
    "                                df = pd.read_csv(os.path.join(root,f), \n",
    "                                                keep_default_na=False)\n",
    "                                df.columns=[c.lower() for c in df.columns]\n",
    "                                dfref=pd.read_sql(f'select * from geostandardise_src.{t} limit 1',c.sqlAlchemyConn)\n",
    "                                colonnesEnTrop=[c.lower() for c in df.columns if c not in dfref.columns]\n",
    "                                df.drop(colonnesEnTrop,axis=1).to_sql(t,c.sqlAlchemyConn,'geostandardise_src', if_exists='append', index=False )\n",
    "                            except Exception as e :\n",
    "                                print(f'Erreur sur : {os.path.join(root,f)} : {e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour test sur un dept\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr,r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Bretagne\\35\\N_ROUTIER_TRONCON_L_035.shp',\n",
    "                                              schema='geostandardise_src', table='troncon_national',\n",
    "                                              SRID='2154',geotype='MULTILINESTRING', dims=3, creationMode='-append -update',encodageClient='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sur un fichier\n",
    "with ct.ConnexionBdd('local_PlaMADE', 'maison') as c :\n",
    "    ct.ogr2ogr_shp2pg(c.connstringOgr,r'C:\\Users\\martin.schoreisz\\Box\\Donnees_source\\Donnees_geostandardisees\\Auvergne_Rhone_Alpes\\Donnees_geostandardisees\\Route01_v2_dec2020\\N_ROUTIER_ALLURE_001.dbf',\n",
    "                                                  schema='geostandardise_src', table='allure_national', SRID=None,geotype=None, dims=None, creationMode='-append -update',encodageClient='UTF-8', requeteSql='', version_simple=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Générer un fichier unique trafic RD\n",
    "> L'idée est de se baser sur le fichier de résumé des fichiers gestionnaires et de leurs attributs pour produire un fichier concaténé, avec des attributs uniques relatifs au :\n",
    "- tmja\n",
    "- pcpl\n",
    "- nom de la voie\n",
    "- annee du trafic\n",
    "- fichier source (sur Box internet)\n",
    "- nom de la source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Principe mise en forme des fichiers \n",
    ">> Pour faire ça on va aller chercher le [fichier de synthses des données RD] (https://cerema.app.box.com/folder/132749694470/Synthese_type_fichier.ods).\n",
    "dans l'onglet trafic, on va itérer sur chaque ligne (donc récupération du tuple de valeur) : \n",
    ">> On limite l'analyse aux données présentant un colonne valide='oui' & type='sig' & type_geom='ligne'  \n",
    "1. on récupere la valeur de la colonne \"nom_fichier_trafic\" :\n",
    "    1. si l'extenstion est présente, on va lire le fichier (attention, via box Drive, donc paramètre de raw string en entrée)\n",
    "    1. l'attribut relatif au tmja est toujours présent, celui au pc_pl parfois, comme pour les routes ou l'année, mais comme la fonction rename s'en fout, on fait le rename des 4 colonnes\n",
    "    1. si des formules sont à appliquer, on les applique (liées au pcpl, et nom de route notamment\n",
    "    1. gérer le format des dates pour l'année de mesure\n",
    "    1. ajouter les attributs sur le fichiers sources, le nom de la source, le type de source\n",
    "    1. enregistrer le fichier mise en forme dans le dossier qui va bien (paramètre entrée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir le fichiers de syntheses des données\n",
    "dossierDonneesRd=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD'\n",
    "fichierSynthese=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD\\Synthese_type_fichier.ods'\n",
    "dfFichierSynthese=pd.read_excel(fichierSynthese, sheet_name='Complet',engine='odf', nrows=35, dtype={'dept':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer le generateurde parcours des valeusr en tuple\n",
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion']!='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='ligne')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'ajout des sources de données\n",
    "def ajouterSourceDonnees(tupleNomAttr, dfFichierRenomme, fihcierSource) : \n",
    "    \"\"\"\n",
    "    ajouter les nomsource, fichier source et type de source aux donnees mise en formes\n",
    "    in : \n",
    "        tupleNomAttr : tuple des noms d'attributs recherche dans le fchier source\n",
    "        dfFichierRenomme : gdf : contient la trsucture attributaire prevue, apres calcul\n",
    "        fihcierSource : String : nom du fichier source\n",
    "    \"\"\"\n",
    "    dfFichierRenomme['nomsource']='CD_'+tupleNomAttr.dept\n",
    "    dfFichierRenomme['fichie_src']=fihcierSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'ouverture et reprojection en 2154\n",
    "def ouvrirReprojeter(cheminFichier, tupleNomAttr):\n",
    "    \"\"\"\n",
    "    tupleNomAttr : tuple des noms d'attributs recherche dans le fchier source\n",
    "    \"\"\"\n",
    "    dfFichierSource=gp.read_file(cheminFichier, crs=tupleNomAttr.projection)\n",
    "    dfFichierSource=dfFichierSource.to_crs('epsg:2154')\n",
    "    return dfFichierSource\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de calcul regroupant les traitements propres a chaque dept ayant des regles de gestion\n",
    "\n",
    "def calculSpecifique(dfFichierSource, t, listAttrNonNull, typeAtr='trafic') : \n",
    "    \"\"\"\n",
    "    calculer les valeur de tmja, pcpl, nom route et année dans les cas particuklier ou des regles de gestion sont necessaire\n",
    "    in : \n",
    "        dfFichierSource : gdf : gdf issue des fichiers osurces gestionnaiere\n",
    "        t : tuple des noms d'attributs recherche dans le fchier source\n",
    "        listAttrNonNull : list des attributs present dans le fichier (ayant une valuer non nulle)\n",
    "        typeAtr : str : 'trafic' ou 'vts' ou'rvt' defaukt 'trafic' : traduit le type de thématique du fichier ouvert\n",
    "    out : \n",
    "        dfFichierRenomme : gdf : contient la trsucture attributaire prevue, apres calcul\n",
    "    \"\"\"\n",
    "    dicoRvt={'ECF':['ECF','Réparations localisées','Pavés','Bicouche','GLG bicouche','PAVES','Enrobé Coulé à Froid','ENROBE COULE A FROID','ECF cl. A Bicouche 0/10','Pavés','ENROBES COULES A FROID',\n",
    "                   'ECF cl. A Bicouche 0/6,3'],\n",
    "             'BBSG': ['Béton bitumineux','BBSG','Inversé','BBSG (10% recycle)','BBSG (10%)','BBSG (20%)','BBSG (30%)','BBSG (BT)','Colbifibre','COLBIFIBRE','RCS','REPRO','RSC',\n",
    "                     'Enrobés','AUTRE','EB10','Béton Bitumineux Autre','Béton Bitumineux Froid','EB10 Tiède','Revêtement Haute Adhérence','Non connu','Non Revêtu',\n",
    "                     'PATA','CALIBRAGE','ENROBE','REPROFILAGE','?','-','BB','BBF','BBS','BBSG','EME','GB','TN18','X','BB','BBF', 'ENROBE SEMI-GRENU', 'ENROBES'],\n",
    "             'ES' : ['ESU','Produits Spéciaux','Monocouche DG','Monocouche MG','ESGL','ESGLg','ESGLG','ESLG','ESLG 6/10','ESLGg','ESLGl','ESLGLg','Enduit','Enduit Superficiel',\n",
    "                    'ENDUIT SUPERFICIEL','ESEPAIS','AC','ES','ESBIC','ESGLG','ESMDG','ESMONO', 'ESU', 'ENDUITS SUPERFICIELS', 'REPROFILAGE'],\n",
    "             'BBME' : ['BBME','BBME (10% recycle)', 'ENROBE MINCE A MODULE ELEVE',],\n",
    "             'BBM' : ['BBS', 'BBM','BBMA','BBMA phonique','BBMA PHONIQUE', 'BBMPHO','ENROBE MINCE','BBMa', 'BBMa '],\n",
    "             'BBTM' : ['BBTM','BBHM','Béton Bitumineux Très Mince','BB Très Mince Acoustique', 'BBTMPHO','ENROBE TRES MINCE'],\n",
    "            'BBUM': ['BBUM','ULTRA MINCE','ENROBE ULTRA MINCE'],\n",
    "            'BBDr':['BBDR',],\n",
    "            'BC':['BC','BBC']}\n",
    "    \n",
    "    def defRvt(rvt):\n",
    "        if rvt :\n",
    "            try : \n",
    "                rvtOk=[k for k, v in dicoRvt.items() if rvt in v][0]\n",
    "            except IndexError : \n",
    "                print(f'ATTENTION {rvt}')\n",
    "                return None\n",
    "        else :\n",
    "            return None\n",
    "        return rvtOk\n",
    " \n",
    "    if t.dept=='012' : \n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TMJATV2015'] if not pd.isnull(x['TMJATV2015']) else x['TMJA_TV'], axis=1)\n",
    "        dfFichierSource['annee']=dfFichierSource.apply(lambda x : re.match('2[0-9]{3]',x['COMMENTAIR']) if not pd.isnull(x['COMMENTAIR']) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='002': \n",
    "        dfFichierSource['rvtType']=dfFichierSource.apply(lambda x : defRvt(x['NatureCouc']) if not pd.isnull(x['NatureCouc']) else None, axis=1)\n",
    "        dfFichierSource['anneePose']=dfFichierSource.apply(lambda x : str(x.AnneeCouch) if not x.AnneeCouch[0]=='<' else str(x.AnneeCouch)[1:], axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee',t.nom_attr_trafic:'trafic',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_granulo:'granulo'})\n",
    "    elif t.dept=='025' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TMJA'] if x['%_PL']!='D' else None, axis=1)\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['%_PL']) if x['%_PL']!='D' else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='027' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.F_PL.apply(lambda x : x.replace('%','').replace(',','.') if not pd.isnull(x) else None)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee',t.nom_attr_route:'nomRoute',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='031' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.route.apply(lambda x : O.epurationNomRoute(x))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='037' :\n",
    "        if typeAtr=='vts' :\n",
    "            dfFichierSource['nomRoute']=dfFichierSource.axe.apply(lambda x : x.split('_')[1])\n",
    "        elif  typeAtr=='rvt' :\n",
    "            dfFichierSource['nomRoute']=dfFichierSource.IDROUTE.apply(lambda x : x.split('_')[1])\n",
    "            dfFichierSource['rvtType']=dfFichierSource.CG_TYPECOU.apply(lambda x : defRvt(x))\n",
    "        else :\n",
    "            dfFichierSource['nomRoute']=dfFichierSource.idroute.apply(lambda x : x.split('_')[1])\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='046': \n",
    "        dfFichierSource['trafic']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[0] if not pd.isnull(x) else None)\n",
    "        dfFichierSource['annee']=dfFichierSource['MJA TV (an'].apply(lambda x : x.replace(' ','').split('(')[1][:-1] if not pd.isnull(x) and '(' in x else None)\n",
    "        dfFichierSource['pcpl']=dfFichierSource['%PL'].apply(lambda x : float(x)*100 if not pd.isnull(x) else None)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource['RD'].apply(lambda x : x.replace(' ','').replace('RD','D'))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='049' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.Route.apply(lambda x : O.epurationNomRoute(x[3:]))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='052' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['MJA_PL']/x['MJA_TV']*100) if not pd.isnull(x['MJA_TV']) else None, axis=1)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.Route.apply(lambda x : O.epurationNomRoute(x))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='058' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : x['TRAFFIC_VL']+x['TRAFFIC_PL'], axis=1)\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['TRAFFIC_PL']/(x['TRAFFIC_VL']+x['TRAFFIC_PL'])*100) if x['TRAFFIC_VL']+x['TRAFFIC_PL']>0 else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='059' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.VOIE.apply(lambda x : O.epurationNomRoute(x[1:]))\n",
    "        dfFichierSource['rvtType']=dfFichierSource.apply(lambda x : defRvt(x['TYP_DE_REV']) if not pd.isnull(x['TYP_DE_REV']) else defRvt(x['C_D_C_DE_S']), axis=1)\n",
    "        dfFichierSource['granulo']=dfFichierSource.apply(lambda x : re.match(r'([0-9]{1,2}/[0-9]{1,2})',x.GRANULOMET)[0] if not pd.isnull(x.GRANULOMET) and re.match(r'([0-9]/[0-9])',x.GRANULOMET) else None, axis=1)\n",
    "        dfFichierSource['anneePose']=dfFichierSource.apply(lambda x : str(x.D_D_C_DE_S)[:4] if not pd.isnull(x.D_D_C_DE_S) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl'})\n",
    "    elif t.dept=='060' :\n",
    "        if  typeAtr=='trafic' :\n",
    "            dfFichierSource['pcpl']=dfFichierSource.PCT_PL_SEM.apply(lambda x : x.replace('%PL','') if not x=='%PL' else None)\n",
    "            dfFichierSource['annee']=dfFichierSource.DATE_COMPT.str[-4:]\n",
    "        elif typeAtr=='rvt': \n",
    "            dfFichierSource['rvtType']=dfFichierSource.NATURE_C_R.apply(lambda x : defRvt(x.split('_')[0] if not pd.isnull(x) else None))\n",
    "            dfFichierSource['granulo']=dfFichierSource.apply(lambda x : re.match(r'([0-9]{1,2}/[0-9]{1,2})',x.NATURE_C_R)[0] if not pd.isnull(x.NATURE_C_R) and re.match(r'([0-9]/[0-9])',x.NATURE_C_R) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_route:'nomRoute',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    if t.dept=='067' :\n",
    "        if typeAtr=='rvt': \n",
    "            dfFichierSource['rvtType']=dfFichierSource.REVET.apply(lambda x : defRvt(x))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_route:'nomRoute',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_annee_pose : 'anneePose',t.nom_attr_revetement:'granulo'}) \n",
    "    if t.dept=='068' : \n",
    "        if typeAtr=='rvt': \n",
    "            dfFichierSource['rvtType']=dfFichierSource.ROULEMENT_.apply(lambda x : defRvt(x))\n",
    "            dfFichierSource['granulo']=dfFichierSource.apply(lambda x : re.match(r'([0-9]{1,2}/[0-9]{1,2})',x.ROULEMEN_1)[0] if not pd.isnull(x.ROULEMEN_1) and re.match(r'([0-9]/[0-9])',x.ROULEMEN_1) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_route:'nomRoute',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_annee_pose : 'anneePose'})             \n",
    "    elif t.dept=='070':\n",
    "        for c in [f'TA_TV{i}' for i in range(10,19)]: \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False, axis=1),'trafic']= dfFichierSource[c]\n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1),'pcpl']=(dfFichierSource.loc[dfFichierSource.apply(\n",
    "                lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c.replace('TV','PL')]), axis=1)/\n",
    "              dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c.replace('TV','PL')])>0 if not pd.isnull(x[c.replace('TV','PL')]) else False, axis=1)].apply(lambda x : float(x[c]), axis=1)*100)                \n",
    "            dfFichierSource.loc[dfFichierSource.apply(lambda x : float(x[c])>0 if not pd.isnull(x[c]) else False , axis=1),'annee']= f'20{c[-2:]}'\n",
    "            dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_route:'nomRoute',\n",
    "                                                            t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='075' :\n",
    "        dfFichierSource['trafic']=dfFichierSource.apply(lambda x : (x['MT']*12)+(x['ME']*4)+(x['MN']*8) if not (pd.isnull(x['MT']) and pd.isnull(x['ME']) and pd.isnull(x['MN'])) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept =='080' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource[t.nom_attr_route].str[3:]\n",
    "        dfFichierSource['rvtType']=dfFichierSource.apply(lambda x : defRvt(x['NATURE']) if not pd.isnull(x['NATURE']) else None, axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='082' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource[t.nom_attr_route].str[3:]\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept =='076' : \n",
    "        dfFichierSource['nomRoute']=dfFichierSource[t.nom_attr_route].apply(lambda x : O.epurationNomRoute(x[3:]) if x[:2]!='VC' else x )\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic',t.nom_attr_pcpl:'pcpl', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='077' :\n",
    "        dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : str(x['PLTMJA']/x['TVTMJA']*100) if not pd.isnull(x['TVTMJA']) else None, axis=1)\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.ROUTE.apply(lambda x : O.epurationNomRoute(x[2:]))\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_trafic:'trafic', t.nom_attr_annee:'annee',\n",
    "                                                        t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    elif t.dept=='083' :\n",
    "        dfFichierSource['nomRoute']=dfFichierSource.ROUTE.apply(lambda x : O.epurationNomRoute(x[3:]))\n",
    "        if typeAtr=='vts' :\n",
    "            dfFichierSource['vtsvl']=dfFichierSource.PARAMETRES.apply(lambda x : float(x[10:12]) if not pd.isnull(x) else None)\n",
    "        elif typeAtr=='trafic' :        \n",
    "            dfFichierSource['trafic']=dfFichierSource.apply(lambda x : int(x['MJA_2018']) if int(x['MJA_2018'])>0 else int(x['MJA_2017']), axis=1)\n",
    "            dfFichierSource['pcpl']=dfFichierSource.apply(lambda x : x['PL_2018'] if int(x['MJA_2018'])>0 else str(int(x['PL_2017'])/10), axis=1)\n",
    "            dfFichierSource['annee']=dfFichierSource.apply(lambda x : '2018' if int(x['MJA_2018'])>0 else '2017', axis=1)       \n",
    "        else : \n",
    "            dfFichierSource['rvtType']=dfFichierSource.apply(lambda x : defRvt(x.MATERIAU) if not pd.isnull(x.MATERIAU) else defRvt(x.REVETEMENT), axis=1)\n",
    "        dfFichierRenomme=dfFichierSource.rename(columns={t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'})\n",
    "    return dfFichierRenomme[listAttrNonNull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Concat des donnees \n",
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            \"\"\"if t.dept  not in  ('027') : \n",
    "                continue\"\"\"\n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #print(listAttrNonNull)\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('012','027', '037', '049', '052', '058', '059', '060', '075', '077','082', '083', '076','080'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcat=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "#tagguer les geoms nulles \n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'D:\\Boulot\\AffairesEnCours\\plamade\\RDs\\concat\\RD_concatenation_trafic_lineaire.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.2 Principe mise en forme des fichiers ponctuels\n",
    ">> on va garder la structure précédente, mais il va aussi falloir ajouter les 2 jeu de données en tableur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion']!='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide']=='oui') & (dfFichierSynthese['type']=='sig') & (dfFichierSynthese['type_geom']=='point')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            \"\"\"if t.dept  not in  ('046') : \n",
    "                continue\"\"\"\n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #print(f)\n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('025','031', '070', '046'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "#tagguer les geoms nulles \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "dfConcat.loc[dfConcat.nomsource=='CD_008', 'annee']='2018'\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)\n",
    "\n",
    "#toutes les geoms en multi\n",
    "dfConcat[\"geometry\"] = [MultiPoint([feature]) if isinstance(feature, Point) else feature for feature in dfConcat[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'D:\\Boulot\\AffairesEnCours\\plamade\\RDs\\concat\\RD_concatenation_trafic_ponctuel.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Générer un fichier unique RD  \n",
    "sur la base de ce qui a été fait au dessus, on ajouter le revetement et la vitesse quand ils sont disponible au sein du même fichier source, pour les lignes puis les points.  \n",
    "ensuite il faut voir pour les fihiers multiples, on va plutot essayer de regrouper l'info au sein d'un seul fichier prétraité qui regroupera toute les infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.1 fichier lignes avec un seul fichier source et tous les attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierDonneesRd=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD'\n",
    "fichierSynthese=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD\\Synthese_type_fichier.ods'\n",
    "dfFichierSynthese=pd.read_excel(fichierSynthese, sheet_name='Complet',engine='odf', nrows=35, dtype={'dept':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']=='non') & (dfFichierSynthese['fichier_unique']=='oui')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']!='non') & (dfFichierSynthese['fichier_unique']=='oui')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne')\n",
    "                                 & (dfFichierSynthese['fichier_unique']=='oui')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012\n",
      "013\n",
      "027\n",
      "035\n",
      "036\n",
      "044\n",
      "045\n",
      "048\n",
      "049\n",
      "050\n",
      "052\n",
      "058\n",
      "059\n",
      "066\n",
      "071\n",
      "075\n",
      "076\n",
      "077\n",
      "080\n",
      "082\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        if t.dept  in  ('037','067', '068','083') : \n",
    "                continue\n",
    "        for f in files : \n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #print(f)\n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee',\n",
    "                             t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('012','027', '037', '049', '052', '058', '059', '060', '075', '077','082', '083', '076','080'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "#tagguer les geoms nulles \n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)\n",
    "\n",
    "#passage des NaN sur rvtType, granulo, anneePose en None\n",
    "dfConcat.loc[pd.isnull(dfConcat.rvtType), 'rvtType']=None\n",
    "dfConcat.loc[pd.isnull(dfConcat.granulo), 'granulo']=None\n",
    "dfConcat.loc[pd.isnull(dfConcat.anneePose), 'anneePose']=None\n",
    "\n",
    "#coller la granulo sur les codes Enumeres\n",
    "def granuloStandard(granulo) : \n",
    "    dico_granulo={'0/4' : ['0/4',],\n",
    "                    '0/6' : ['0/6',],\n",
    "                    '0/8' : ['0/8',],\n",
    "                    '0/10 type 1' : ['0/10','0/10 type 1'],\n",
    "                    '0/10 type 2' : ['0/10 type 2',],\n",
    "                    '0/14' : ['0/14',],\n",
    "                    '4/6' : ['4/6',],\n",
    "                    '6/8' : ['6/8','5/8'],\n",
    "                    '6/10' : ['6/10'],\n",
    "                    '10/14': ['10/14']}\n",
    "    if granulo : \n",
    "        granuloOk=[k for k, v in dico_granulo.items() if granulo in v][0]\n",
    "    else : \n",
    "        return None\n",
    "    return granuloOk\n",
    "dfConcat['granulo']=dfConcat.granulo.apply(lambda x : granuloStandard(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '2017', '2014', '2009', '2004', '1990', '2011', '2012',\n",
       "       '2016', '2015', '2007', '2005', '2010', '2018', '2000', '2008',\n",
       "       '2002', '2006', '1997', '2003', '2019', '1984', '2001', '1998',\n",
       "       '1995', '1999', '2013', '1994', '1991', '1985', '1996', '1950',\n",
       "       '1978', '1987', '1993', '1960'], dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple de verifs\n",
    "dfConcat.granulo.unique()\n",
    "dfConcat.anneePose.unique()\n",
    "#dfConcat.rvtType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\Bruit\\PLAMADE\\Donnees_GT_flash\\donnees_produites\\Concat_RDs\\Concat_RDs_tousAttributs_1Fichier_lineaire.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.2 fichier point avec un seul fichier source et tous les attributs (il n' y a pas de fichiers point multiples pour plusieurs attributs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierDonneesRd=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD'\n",
    "fichierSynthese=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD\\Synthese_type_fichier.ods'\n",
    "dfFichierSynthese=pd.read_excel(fichierSynthese, sheet_name='Complet',engine='odf', nrows=35, dtype={'dept':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='point')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']!='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='point')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002\n",
      "008\n",
      "025\n",
      "031\n",
      "039\n",
      "046\n",
      "070\n",
      "089\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            \"\"\"if t.dept  not in  ('046') : \n",
    "                continue\"\"\"\n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #print(f)\n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee',\n",
    "                            t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl', t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('002','025','031', '070', '046'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "#tagguer les geoms nulles \n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)\n",
    "\n",
    "#passage des NaN sur rvtType, granulo, anneePose en None\n",
    "dfConcat.loc[pd.isnull(dfConcat.rvtType), 'rvtType']=None\n",
    "#dfConcat.loc[pd.isnull(dfConcat.granulo), 'granulo']=None\n",
    "dfConcat.loc[pd.isnull(dfConcat.anneePose), 'anneePose']=None\n",
    "\n",
    "#toutes les geoms en multi\n",
    "dfConcat[\"geometry\"] = [MultiPoint([feature]) if isinstance(feature, Point) else feature for feature in dfConcat[\"geometry\"]]\n",
    "\n",
    "#coller la granulo sur les codes Enumeres\n",
    "def granuloStandard(granulo) : \n",
    "    dico_granulo={'0/4' : ['0/4',],\n",
    "                    '0/6' : ['0/6',],\n",
    "                    '0/8' : ['0/8',],\n",
    "                    '0/10 type 1' : ['0/10','0/10 type 1'],\n",
    "                    '0/10 type 2' : ['0/10 type 2',],\n",
    "                    '0/14' : ['0/14',],\n",
    "                    '4/6' : ['4/6',],\n",
    "                    '6/8' : ['6/8','5/8'],\n",
    "                    '6/10' : ['6/10'],\n",
    "                    '10/14': ['10/14']}\n",
    "    if granulo : \n",
    "        granuloOk=[k for k, v in dico_granulo.items() if granulo in v][0]\n",
    "    else : \n",
    "        return None\n",
    "    return granuloOk\n",
    "#dfConcat['granulo']=dfConcat.granulo.apply(lambda x : granuloStandard(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BBSG', 'ES', nan], dtype=object)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple de verifs\n",
    "#dfConcatFixe.granulo.unique()\n",
    "#dfConcatFixe.anneePose.unique()\n",
    "dfConcat.rvtType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\Bruit\\PLAMADE\\Donnees_GT_flash\\donnees_produites\\Concat_RDs\\Concat_RDs_tousAttributs_1Fichier_ponctuel.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.3 fichier lineaire avec un plusiuers fichier source ; attributs trafic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierDonneesRd=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD'\n",
    "fichierSynthese=r'C:\\Users\\martin.schoreisz\\Box\\Projet PLaMADE\\PLAMADE\\Reprise PlaMADE-Projet Sword\\Données\\3-RD\\Synthese_type_fichier.ods'\n",
    "dfFichierSynthese=pd.read_excel(fichierSynthese, sheet_name='Complet',engine='odf', nrows=35, dtype={'dept':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNettoyeesSansReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']=='non') & (dfFichierSynthese['fichier_unique']=='non')].copy()\n",
    "dfNettoyeesAvecReglesGestion=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne')\n",
    "                                 & (dfFichierSynthese['regles_gestion_trafic']!='non') & (dfFichierSynthese['fichier_unique']=='non')].copy()\n",
    "dfNettoyees=dfFichierSynthese.loc[(dfFichierSynthese['valide_trafic']=='oui') & (dfFichierSynthese['type_trafic']=='sig') & (dfFichierSynthese['type_geom_trafic']=='ligne') \n",
    "                                 & (dfFichierSynthese['fichier_unique']=='non')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "037\n",
      "060\n",
      "067\n",
      "068\n",
      "083\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            if f.lower() == t.nom_fichier_trafic.lower() : \n",
    "                #print(f)\n",
    "                #ouvrir et modifier le crs si besoin\n",
    "                dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                dicoNomAttr={t.nom_attr_trafic:'trafic', t.nom_attr_pcpl:'pcpl', t.nom_attr_route:'nomRoute',t.nom_attr_annee:'annee'}\n",
    "                listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                if t.dept in ('012','027', '037', '049', '052', '058', '059', '060', '075', '077','082', '083', '076','080'):\n",
    "                    dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull)\n",
    "                else :\n",
    "                    dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "#tagguer les geoms nulles \n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : not pd.isnull(x)), 'geom_nulle']=False\n",
    "dfConcat.loc[dfConcat.geometry.apply(lambda x : pd.isnull(x)), 'geom_nulle']=True\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.annee=dfConcat.annee.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.annee=dfConcat.annee.str[:4]\n",
    "dfConcat.loc[dfConcat.annee.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#mise en forme valeurs TMJA et pcpl : \n",
    "dfConcat.trafic=dfConcat.trafic.apply(lambda x : round(float(x),0) if not pd.isnull(x) else np.nan)\n",
    "dfConcat.pcpl=dfConcat.pcpl.apply(lambda x : round(float(str(x).replace(',','.')),2) if not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\Bruit\\PLAMADE\\Donnees_GT_flash\\donnees_produites\\Concat_RDs\\Concat_RDs_1Attributs_1Fichier_trafic_lineaire.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.3 fichier lineaire avec un plusiuers fichier source ; attributs vitesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "037\n",
      "060\n",
      "067\n",
      "068\n",
      "083\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            if isinstance(t.nom_fichier_vitesse, str) : \n",
    "                #print(f.lower(), t.nom_fichier_vitesse.lower())\n",
    "                if f.lower() == t.nom_fichier_vitesse.lower() : \n",
    "                    #print(f)\n",
    "                    #ouvrir et modifier le crs si besoin\n",
    "                    dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                    dicoNomAttr={t.nom_attr_routevitesse:'nomRoute',t.nom_attr_vtsvl:'vtsvl', t.nom_attr_vtspl:'vtspl'}\n",
    "                    listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                    #print(listAttrNonNull)\n",
    "                    #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                    if t.dept in ('037','083'):\n",
    "                        dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull, ('vts'))\n",
    "                    else :\n",
    "                        dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                    ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "#ajout attribut vts pl pour homogénéïté\n",
    "dfConcat['vtspl']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomRoute</th>\n",
       "      <th>vtsvl</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nomsource</th>\n",
       "      <th>fichie_src</th>\n",
       "      <th>vtspl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>LINESTRING (542436.788 6704593.203, 542447.300...</td>\n",
       "      <td>CD_037</td>\n",
       "      <td>Lim_Vitesse_CD37.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>LINESTRING (543306.486 6704744.750, 543312.500...</td>\n",
       "      <td>CD_037</td>\n",
       "      <td>Lim_Vitesse_CD37.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LINESTRING (551145.358 6707598.390, 551167.200...</td>\n",
       "      <td>CD_037</td>\n",
       "      <td>Lim_Vitesse_CD37.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>LINESTRING (538365.946 6703752.032, 538418.700...</td>\n",
       "      <td>CD_037</td>\n",
       "      <td>Lim_Vitesse_CD37.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>LINESTRING (538900.102 6703933.786, 538915.600...</td>\n",
       "      <td>CD_037</td>\n",
       "      <td>Lim_Vitesse_CD37.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>EV8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LINESTRING (932374.172 6282189.852, 932381.677...</td>\n",
       "      <td>CD_083</td>\n",
       "      <td>ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>EV8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (932846.179 6282184.907, 932856.994...</td>\n",
       "      <td>CD_083</td>\n",
       "      <td>ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>EV8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (938426.166 6282211.992, 938436.133...</td>\n",
       "      <td>CD_083</td>\n",
       "      <td>ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>EV8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (940457.766 6280295.614, 940465.388...</td>\n",
       "      <td>CD_083</td>\n",
       "      <td>ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>EV8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LINESTRING (955199.749 6279530.386, 955209.521...</td>\n",
       "      <td>CD_083</td>\n",
       "      <td>ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nomRoute  vtsvl                                           geometry  \\\n",
       "0         D1   70.0  LINESTRING (542436.788 6704593.203, 542447.300...   \n",
       "1         D1   70.0  LINESTRING (543306.486 6704744.750, 543312.500...   \n",
       "2         D1   50.0  LINESTRING (551145.358 6707598.390, 551167.200...   \n",
       "3         D1   70.0  LINESTRING (538365.946 6703752.032, 538418.700...   \n",
       "4         D1   70.0  LINESTRING (538900.102 6703933.786, 538915.600...   \n",
       "..       ...    ...                                                ...   \n",
       "357      EV8   50.0  LINESTRING (932374.172 6282189.852, 932381.677...   \n",
       "358      EV8   30.0  LINESTRING (932846.179 6282184.907, 932856.994...   \n",
       "359      EV8   30.0  LINESTRING (938426.166 6282211.992, 938436.133...   \n",
       "360      EV8   30.0  LINESTRING (940457.766 6280295.614, 940465.388...   \n",
       "361      EV8   30.0  LINESTRING (955199.749 6279530.386, 955209.521...   \n",
       "\n",
       "    nomsource                                 fichie_src vtspl  \n",
       "0      CD_037                       Lim_Vitesse_CD37.shp  None  \n",
       "1      CD_037                       Lim_Vitesse_CD37.shp  None  \n",
       "2      CD_037                       Lim_Vitesse_CD37.shp  None  \n",
       "3      CD_037                       Lim_Vitesse_CD37.shp  None  \n",
       "4      CD_037                       Lim_Vitesse_CD37.shp  None  \n",
       "..        ...                                        ...   ...  \n",
       "357    CD_083  ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp  None  \n",
       "358    CD_083  ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp  None  \n",
       "359    CD_083  ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp  None  \n",
       "360    CD_083  ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp  None  \n",
       "361    CD_083  ARRETE_LIMITATION_VITESSE_ROUTE83_ORL.shp  None  \n",
       "\n",
       "[5433 rows x 6 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple de vérif\n",
    "dfConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\Bruit\\PLAMADE\\Donnees_GT_flash\\donnees_produites\\Concat_RDs\\Concat_RDs_1Attributs_1Fichier_trafic_vitesse.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3.3 fichier lineaire avec un plusiuers fichier source ; attributs revetement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "037\n",
      "['nomRoute', 'rvtType', 'granulo', 'anneePose', 'geometry'] {'IDROUTE': 'nomRoute', 'CG_TYPECOU': 'rvtType', 'CG_TYPEG_1': 'granulo', 'CGDT_MODIF': 'anneePose'}\n",
      "060\n",
      "['nomRoute', 'rvtType', 'geometry'] {'AXE': 'nomRoute', 'NATURE_C_R': 'rvtType', nan: 'anneePose'}\n",
      "067\n",
      "['nomRoute', 'rvtType', 'geometry'] {'AXE': 'nomRoute', 'REVET': 'rvtType', nan: 'anneePose'}\n",
      "068\n",
      "['nomRoute', 'rvtType', 'granulo', 'anneePose', 'geometry'] {'AXE': 'nomRoute', 'ROULEMENT_': 'rvtType', 'ROULEMEN_1': 'granulo', 'ANNEE': 'anneePose'}\n",
      "083\n",
      "['nomRoute', 'rvtType', 'anneePose', 'geometry'] {'ROUTE': 'nomRoute', 'REVETEMENT, MATERIAU': 'rvtType', nan: 'granulo', 'ANNEE': 'anneePose'}\n"
     ]
    }
   ],
   "source": [
    "dicoGdf={}\n",
    "for t in dfNettoyees.itertuples() : \n",
    "    #ouvrir le fichier\n",
    "    print(t.dept)\n",
    "    for root, dirs, files in os.walk(os.path.join(dossierDonneesRd, t.dept)) : \n",
    "        for f in files : \n",
    "            if isinstance(t.nom_fichier_revetement, str) : \n",
    "                #print(f.lower(), t.nom_fichier_vitesse.lower())\n",
    "                if f.lower() == t.nom_fichier_revetement.lower() : \n",
    "                    #print(f)\n",
    "                    #ouvrir et modifier le crs si besoin\n",
    "                    dfFichierSource=ouvrirReprojeter(os.path.join(root, f),t)\n",
    "                    dicoNomAttr={t.nom_attr_route_rvt:'nomRoute',t.nom_attr_revetement:'rvtType',t.nom_attr_granulo:'granulo', t.nom_attr_annee_pose : 'anneePose'}\n",
    "                    listAttrNonNull=[v for k,v in dicoNomAttr.items() if not pd.isnull(k)]+['geometry']\n",
    "                    print(listAttrNonNull,dicoNomAttr )\n",
    "                    #a reprendre apres pour le cas des departements particuliers non traites\n",
    "                    if t.dept in ('037','060','067','068','083',):\n",
    "                        dfFichierRenomme=calculSpecifique(dfFichierSource, t, listAttrNonNull, ('rvt'))\n",
    "                    else :\n",
    "                        dfFichierRenomme=dfFichierSource.rename(columns=dicoNomAttr)[listAttrNonNull]\n",
    "                    ajouterSourceDonnees(t, dfFichierRenomme, f)\n",
    "    dicoGdf[t.dept]=dfFichierRenomme\n",
    "dfConcatFixe=pd.concat(dicoGdf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitemnets avant export : \n",
    "dfConcat=dfConcatFixe.copy()\n",
    "\n",
    "#corriger des valeurs louches sur les annees et passer en format date AAAA pour le reste\n",
    "dfConcat.anneePose=dfConcat.anneePose.apply(lambda x : str(x) if not pd.isnull(x) else None)\n",
    "dfConcat.anneePose=dfConcat.anneePose.str[:4]\n",
    "dfConcat.loc[dfConcat.anneePose.apply(lambda x : float(x)<1950 if not (pd.isnull(x)) else True), 'annee']=None\n",
    "\n",
    "#passage des NaN sur rvtType, granulo, anneePose en None\n",
    "dfConcat.loc[pd.isnull(dfConcat.rvtType), 'rvtType']=None\n",
    "dfConcat.loc[pd.isnull(dfConcat.granulo), 'granulo']=None\n",
    "dfConcat.loc[pd.isnull(dfConcat.anneePose) | (dfConcat.anneePose=='0'), 'anneePose']=None\n",
    "\n",
    "#coller la granulo sur les codes Enumeres\n",
    "def granuloStandard(granulo) : \n",
    "    dico_granulo={'0/4' : ['0/4','2/4'],\n",
    "                    '0/6' : ['0/6','0/5'],\n",
    "                    '0/8' : ['0/8',],\n",
    "                    '0/10 type 1' : ['0/10','0/10 type 1', '-', '10/1','/100', '0/25'],\n",
    "                    '0/10 type 2' : ['0/10 type 2',],\n",
    "                    '0/14' : ['0/14','0/20', '0/31'],\n",
    "                    '4/6' : ['4/6', '6/4', '4/06'],\n",
    "                    '6/8' : ['6/8','5/8'],\n",
    "                    '6/10' : ['6/10','4/10'],\n",
    "                    '10/14': ['10/14']}\n",
    "    try :\n",
    "        if granulo : \n",
    "            granuloOk=[k for k, v in dico_granulo.items() if granulo in v][0]\n",
    "        else : \n",
    "            return None\n",
    "    except IndexError : \n",
    "        print(granulo)\n",
    "    return granuloOk\n",
    "dfConcat['granulo']=dfConcat.granulo.apply(lambda x : granuloStandard(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '0/10 type 1', '4/6', '0/6', '6/10', '10/14', '0/4', '0/14',\n",
       "       '0/8', '6/8'], dtype=object)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple verifs\n",
    "dfConcat.rvtType.unique()\n",
    "dfConcat.granulo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dfConcat.to_file(r'C:\\Users\\martin.schoreisz\\Box\\Dossier_Perso\\Bruit\\PLAMADE\\Donnees_GT_flash\\donnees_produites\\Concat_RDs\\Concat_RDs_1Attributs_1Fichier_Revetement_lineaire.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
